{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Enhancing Explainability in Credit Scoring</span></center>\n",
    "## <span style=\"font-family: ClearSans, sans-serif; color:navyblue\">Dataset</span>\n",
    "\n",
    "\n",
    "<span style=\"font-family: ClearSans, sans-serif; color:navyblue\">Author: <a href=\"https://github.com/deburky\" title=\"GitHub link\">https://github.com/deburky</a></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Dataset A: FICO xML Challenge</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_A = pd.read_csv(\"data/dataset_A.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing target variables\n",
    "dataset_A[\"RiskPerformance\"].replace({\"Good\": 0, \"Bad\": 1}, inplace=True)\n",
    "dataset_A.rename(columns={\"RiskPerformance\": \"is_bad\"}, inplace=True)\n",
    "\n",
    "# processing special codes\n",
    "special_codes = [-9, -8, -7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dataset_A = [\n",
    "    \"ExternalRiskEstimate\",\n",
    "    \"MSinceOldestTradeOpen\",\n",
    "    \"MSinceMostRecentTradeOpen\",\n",
    "    \"AverageMInFile\",\n",
    "    \"NumSatisfactoryTrades\",\n",
    "    \"NumTrades60Ever2DerogPubRec\",\n",
    "    \"NumTrades90Ever2DerogPubRec\",\n",
    "    \"PercentTradesNeverDelq\",\n",
    "    \"MSinceMostRecentDelq\",\n",
    "    \"NumTradesOpeninLast12M\",\n",
    "    \"MSinceMostRecentInqexcl7days\",\n",
    "    \"NumInqLast6M\",\n",
    "    \"NumInqLast6Mexcl7days\",\n",
    "    \"NetFractionRevolvingBurden\",\n",
    "    \"NetFractionInstallBurden\",\n",
    "    \"NumBank2NatlTradesWHighUtilization\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_A = dataset_A[feats_dataset_A + [\"is_bad\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10459"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Dataset B: Lending Club</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_B = pd.read_csv(\"data/dataset_B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_B.rename(columns={\"delinq_2y\": \"is_bad\"}, inplace=True)\n",
    "dataset_B[\"is_bad\"] = np.where(dataset_B[\"is_bad\"] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dataset_B = [\n",
    "    \"annual_income\",\n",
    "    \"debt_to_income\",\n",
    "    \"emp_length\",\n",
    "    \"loan_amount\",\n",
    "    \"total_credit_limit\",\n",
    "    \"total_credit_utilized\",\n",
    "    \"current_installment_accounts\",\n",
    "    \"paid_total\",\n",
    "    \"num_mort_accounts\",\n",
    "    \"account_never_delinq_percent\",\n",
    "    \"balance\",\n",
    "    \"num_historical_failed_to_pay\",\n",
    "    \"num_total_cc_accounts\",\n",
    "    \"num_open_cc_accounts\",\n",
    "    \"num_cc_carrying_balance\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_B = dataset_B[feats_dataset_B + [\"is_bad\"]].copy()\n",
    "dataset_B[\"debt_to_income\"] = np.where(\n",
    "    dataset_B[\"debt_to_income\"].isna(), 1, dataset_B[\"debt_to_income\"]\n",
    ")\n",
    "dataset_B[\"emp_length\"] = np.where(\n",
    "    dataset_B[\"emp_length\"].isna(), 0, dataset_B[\"debt_to_income\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Dataset C: Give Me Some Credit</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_C = pd.read_csv(\"data/dataset_C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_C.rename(columns={\"SeriousDlqin2yrs\": \"is_bad\"}, inplace=True)\n",
    "dataset_C[\"MonthlyIncome\"] = np.where(\n",
    "    dataset_C[\"MonthlyIncome\"].isna(), 0, dataset_C[\"MonthlyIncome\"]\n",
    ")\n",
    "dataset_C[\"NumberOfDependents\"] = np.where(\n",
    "    dataset_C[\"NumberOfDependents\"].isna(), 0, dataset_C[\"NumberOfDependents\"]\n",
    ")\n",
    "dataset_C[\"RevolvingUtilizationOfUnsecuredLines\"] = np.clip(\n",
    "    dataset_C[\"RevolvingUtilizationOfUnsecuredLines\"], 0, 1\n",
    ")\n",
    "\n",
    "dataset_C[\"DebtRatio\"] = np.clip(dataset_C[\"DebtRatio\"], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dataset_C = [\n",
    "    \"age\",\n",
    "    \"DebtRatio\",\n",
    "    \"MonthlyIncome\",\n",
    "    \"NumberOfOpenCreditLinesAndLoans\",\n",
    "    \"NumberOfDependents\",\n",
    "    \"NumberRealEstateLoansOrLines\",\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_C = dataset_C[feats_dataset_C + [\"is_bad\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Blending</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_sample_size_bad = 1000\n",
    "\n",
    "# Sample 'is_bad' labels from each dataset\n",
    "bad_A = (\n",
    "    dataset_A[dataset_A[\"is_bad\"] == 1][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_bad, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bad_B = (\n",
    "    dataset_B[dataset_B[\"is_bad\"] == 1][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_bad, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bad_C = (\n",
    "    dataset_C[dataset_C[\"is_bad\"] == 1][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_bad, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Concatenate the \"bad\" rows from all datasets\n",
    "bad_D = (\n",
    "    pd.concat([bad_A, bad_B, bad_C], axis=0)\n",
    "    .sample(n=desired_sample_size_bad, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feat_A = (\n",
    "    dataset_A[dataset_A.is_bad == 1]\n",
    "    .sample(n=len(bad_A), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "feat_B = (\n",
    "    dataset_B[dataset_B.is_bad == 1]\n",
    "    .sample(n=len(bad_B), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "feat_C = (\n",
    "    dataset_C[dataset_C.is_bad == 1]\n",
    "    .sample(n=len(bad_C), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feat_D = pd.concat([feat_A, feat_B, feat_C], axis=1)\n",
    "\n",
    "sample_bads = pd.concat([feat_D, bad_D], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_sample_size_goods = 9000\n",
    "\n",
    "# Sample 'is_bad' labels from each dataset\n",
    "good_A = (\n",
    "    dataset_A[dataset_A[\"is_bad\"] == 0][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_goods, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "good_B = (\n",
    "    dataset_B[dataset_B[\"is_bad\"] == 0][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_goods, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "good_C = (\n",
    "    dataset_C[dataset_C[\"is_bad\"] == 0][\"is_bad\"]\n",
    "    .sample(n=desired_sample_size_goods, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Concatenate the \"bad\" rows from all datasets\n",
    "good_D = (\n",
    "    pd.concat([good_A, good_B, good_C], axis=0)\n",
    "    .sample(n=desired_sample_size_goods, replace=True, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feat_A = (\n",
    "    dataset_A[dataset_A.is_bad == 0]\n",
    "    .sample(n=len(good_A), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "feat_B = (\n",
    "    dataset_B[dataset_B.is_bad == 0]\n",
    "    .sample(n=len(good_B), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "feat_C = (\n",
    "    dataset_C[dataset_C.is_bad == 0]\n",
    "    .sample(n=len(good_C), replace=True, random_state=42)\n",
    "    .drop(columns=\"is_bad\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "feat_D = pd.concat([feat_A, feat_B, feat_C], axis=1)\n",
    "\n",
    "sample_goods = pd.concat([feat_D, good_D], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_D = pd.concat([sample_bads, sample_goods], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_D[\"is_bad\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Renaming and monotonic constraints</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"ExternalRiskEstimate\": {\n",
    "        \"standardized_attribute_name\": \"external_risk_estimate\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"MSinceOldestTradeOpen\": {\n",
    "        \"standardized_attribute_name\": \"months_since_oldest_trade_open\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"MSinceMostRecentTradeOpen\": {\n",
    "        \"standardized_attribute_name\": \"months_since_most_recent_trade_open\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"AverageMInFile\": {\n",
    "        \"standardized_attribute_name\": \"average_months_in_file\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"NumSatisfactoryTrades\": {\n",
    "        \"standardized_attribute_name\": \"num_satisfactory_trades\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"NumTrades60Ever2DerogPubRec\": {\n",
    "        \"standardized_attribute_name\": \"num_trades_60_ever_2_derog_pub_rec\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NumTrades90Ever2DerogPubRec\": {\n",
    "        \"standardized_attribute_name\": \"num_trades_90_ever_2_derog_pub_rec\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"PercentTradesNeverDelq\": {\n",
    "        \"standardized_attribute_name\": \"percent_trades_never_delq\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"MSinceMostRecentDelq\": {\n",
    "        \"standardized_attribute_name\": \"months_since_most_recent_delq\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"NumTradesOpeninLast12M\": {\n",
    "        \"standardized_attribute_name\": \"num_trades_open_in_last_12m\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"MSinceMostRecentInqexcl7days\": {\n",
    "        \"standardized_attribute_name\": \"months_since_most_recent_inqexcl7days\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"NumInqLast6M\": {\n",
    "        \"standardized_attribute_name\": \"num_inq_last_6m\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NumInqLast6Mexcl7days\": {\n",
    "        \"standardized_attribute_name\": \"num_inq_last_6m_excl7days\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NetFractionRevolvingBurden\": {\n",
    "        \"standardized_attribute_name\": \"net_fraction_revolving_burden\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NetFractionInstallBurden\": {\n",
    "        \"standardized_attribute_name\": \"net_fraction_install_burden\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NumBank2NatlTradesWHighUtilization\": {\n",
    "        \"standardized_attribute_name\": \"num_bank_2_natl_trades_w_high_utilization\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"emp_length\": {\"standardized_attribute_name\": \"emp_length\", \"causal_knowledge\": -1},\n",
    "    \"annual_income\": {\n",
    "        \"standardized_attribute_name\": \"annual_income\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"debt_to_income\": {\n",
    "        \"standardized_attribute_name\": \"debt_to_income\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"total_credit_limit\": {\n",
    "        \"standardized_attribute_name\": \"total_credit_limit\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"total_credit_utilized\": {\n",
    "        \"standardized_attribute_name\": \"total_credit_utilized\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"num_historical_failed_to_pay\": {\n",
    "        \"standardized_attribute_name\": \"num_historical_failed_to_pay\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"current_installment_accounts\": {\n",
    "        \"standardized_attribute_name\": \"current_installment_accounts\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"num_total_cc_accounts\": {\n",
    "        \"standardized_attribute_name\": \"num_total_cc_accounts\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"num_open_cc_accounts\": {\n",
    "        \"standardized_attribute_name\": \"num_open_cc_accounts\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"num_cc_carrying_balance\": {\n",
    "        \"standardized_attribute_name\": \"num_cc_carrying_balance\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"num_mort_accounts\": {\n",
    "        \"standardized_attribute_name\": \"num_mort_accounts\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"account_never_delinq_percent\": {\n",
    "        \"standardized_attribute_name\": \"account_never_delinq_percent\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"loan_amount\": {\n",
    "        \"standardized_attribute_name\": \"loan_amount\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"balance\": {\"standardized_attribute_name\": \"balance\", \"causal_knowledge\": 1},\n",
    "    \"paid_total\": {\"standardized_attribute_name\": \"paid_total\", \"causal_knowledge\": -1},\n",
    "    \"age\": {\"standardized_attribute_name\": \"age\", \"causal_knowledge\": -1},\n",
    "    \"DebtRatio\": {\"standardized_attribute_name\": \"debt_ratio\", \"causal_knowledge\": -1},\n",
    "    \"MonthlyIncome\": {\n",
    "        \"standardized_attribute_name\": \"monthly_income\",\n",
    "        \"causal_knowledge\": -1,\n",
    "    },\n",
    "    \"NumberOfOpenCreditLinesAndLoans\": {\n",
    "        \"standardized_attribute_name\": \"number_of_open_credit_lines_and_loans\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NumberRealEstateLoansOrLines\": {\n",
    "        \"standardized_attribute_name\": \"number_real_estate_loans_or_lines\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"NumberOfDependents\": {\n",
    "        \"standardized_attribute_name\": \"number_of_dependents\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "    \"RevolvingUtilizationOfUnsecuredLines\": {\n",
    "        \"standardized_attribute_name\": \"revolving_utilization_of_unsecured_lines\",\n",
    "        \"causal_knowledge\": 1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing names of columns\n",
    "column_mapping = {\n",
    "    col: data_dict[col][\"standardized_attribute_name\"] if col in data_dict else col\n",
    "    for col in dataset_D.columns\n",
    "}\n",
    "\n",
    "dataset_D.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_connected = [\n",
    "    \"percent_trades_never_delq\",\n",
    "    \"account_never_delinq_percent\",\n",
    "    \"total_credit_utilized\",\n",
    "    \"revolving_utilization_of_unsecured_lines\",\n",
    "    \"annual_income\",\n",
    "    \"monthly_income\",\n",
    "    \"debt_ratio\",\n",
    "    \"debt_to_income\",\n",
    "    \"number_of_open_credit_lines_and_loans\",\n",
    "    \"num_total_cc_accounts\",\n",
    "    \"num_open_cc_accounts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: ClearSans, sans-serif; color:#00BBD7\">Removal of redundant features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent_trades_never_delq: 29.84%\n",
      "account_never_delinq_percent: 72.51%\n",
      "total_credit_utilized: 8.31%\n",
      "revolving_utilization_of_unsecured_lines: 54.60%\n",
      "annual_income: -7.80%\n",
      "monthly_income: 5.74%\n",
      "debt_ratio: 9.06%\n",
      "debt_to_income: 10.42%\n",
      "number_of_open_credit_lines_and_loans: 2.93%\n",
      "num_total_cc_accounts: 12.83%\n",
      "num_open_cc_accounts: 1.00%\n"
     ]
    }
   ],
   "source": [
    "X = dataset_D.copy()\n",
    "y = X.pop(\"is_bad\")\n",
    "\n",
    "ix_train, ix_test = train_test_split(X.index, stratify=y, random_state=62)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "for feat in feats_connected:\n",
    "    log_reg.fit(X[feat].loc[ix_train].values.reshape(-1, 1), y.loc[ix_train])\n",
    "    pred = log_reg.predict_proba(X[feat].loc[ix_test].values.reshape(-1, 1))[:, 1]\n",
    "    gini_score = roc_auc_score(y.loc[ix_test], pred) * 2 - 1\n",
    "    print(f\"{feat}: {gini_score:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_D.drop(\n",
    "    columns=[\n",
    "        \"total_credit_utilized\",\n",
    "        \"number_of_open_credit_lines_and_loans\",\n",
    "        \"num_open_cc_accounts\",\n",
    "        \"annual_income\",\n",
    "        \"debt_ratio\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_D.to_parquet(\"blended_dataset.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic_constraints_woe = {}\n",
    "monotonic_constraints_tree = {}\n",
    "\n",
    "for col, attributes in data_dict.items():\n",
    "    standardized_name = attributes[\"standardized_attribute_name\"]\n",
    "    if standardized_name in dataset_D.columns:\n",
    "        # Check the value of 'causal_knowledge' to determine the monotonic constraint\n",
    "        if attributes[\"causal_knowledge\"] == -1:\n",
    "            monotonic_constraints_woe[standardized_name] = {\n",
    "                \"monotonic_trend\": \"descending\"\n",
    "            }\n",
    "            monotonic_constraints_tree[standardized_name] = -1\n",
    "        elif attributes[\"causal_knowledge\"] == 1:\n",
    "            monotonic_constraints_woe[standardized_name] = {\n",
    "                \"monotonic_trend\": \"ascending\"\n",
    "            }\n",
    "            monotonic_constraints_tree[standardized_name] = 1\n",
    "monotonic_constraints_xgb = [value for key, value in monotonic_constraints_tree.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_x86_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
